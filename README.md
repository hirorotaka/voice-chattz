# 🎉 Voice Chatzz 
AI と音声で学ぶ言語学習プラットフォーム

## 🌟 概要

AI と音声認識を組み合わせた次世代の言語学習プラットフォーム。<br>
ブラウザ上でリアルタイムな音声認識により、AI との自然な会話を通じて語学力を向上させることができます。

**サービス URL**: [https://voice-chattz.com](https://voice-chattz.com)

## 💡 開発背景

### 課題認識

-   突発的な「話したい」気持ちを満たせる場所の不足
-   LINE や SNS では相手の時間を考慮する必要がある
-   カウンセリングは敷居が高く、友人に相談するほどでもない悩みの存在

### 解決策として

AI との会話という選択機能を実装することで：

-   時間を気にせず、気軽に話しかけられる相手の提供
-   適切なアドバイスやフィードバックが得られる環境の実現
-   英会話練習や面接練習など、実用的な用途への展開

## ⚡ 主要機能

### 🔐 アカウント管理

-   ユーザー登録・編集・削除
-   ログイン/ログアウト
-   パスワードリセット

### 💬 コミュニケーション

-   **マルチ言語対応チャット**
    -   英語・日本語など目的に応じた言語選択
    -   AI キャラクターとの会話
-   **音声認識チャット**
    -   リアルタイム音声録音
    -   AI 応答システム

### 🤖 AI キャラクター管理

-   **カスタム AI キャラクター作成**
    -   目的に応じたキャラクター設定
    -   他ユーザーとの共有機能
-   **公開 AI キャラクター使用**
    -   コミュニティ作成キャラクターの利用

## 🛠 技術スタック

### バックエンド

-   PHP 8.4
-   Laravel Framework 11.35.1
-   認証機能(Laravel Breeze)
-   MySQL 8.0
-   API 連携 inertiajs/inertia-laravel

### フロントエンド

-   React 18.2.0
-   TypeScript 5.0.2
-   TailwindCSS 3.2.1
-   Flowbite React 0.10.2
-   axios 1.7.4
-   RecordRTC 5.6.2
-   API 連携 inertiajs/react
-   vite 5.4.11

### インフラストラクチャー

-   ホスティング: Heroku
-   メール配信: SendGrid
-   静的コンテンツ配信: S3 + CloudFrontt

### 開発環境

-   docker(Laravel Sail) 開発環境
-   mailpit(開発環境でのメール確認)
-   phpMyAdmin
-   Visual Studio Code
-   API クライアント(Thunder Client)

### 外部 API

-   webAPI OpenAI_API

## 📃 ER 図
![スクリーンショット 2025-02-12 18 25 08](https://github.com/user-attachments/assets/d0e77df0-d213-4f54-91c2-e03ac39966f6)


<br>
<br>
<br>

## 💪 工夫した点

### UI / UX

とにかくユーザーがストレスなく、サクサクと使える UI/UX の実装を図りました。
<br>
<br>

-   メニューなどはサイドバーにすべて配置
-   得たい情報が視覚的にパッと目につくようなページ構成
-   画面全体の読み込みやスクロールをできるだけ減らす
-   モーダルを使用したコンテンツの表示・切り替え
-   パフォーマンス最適化
-   不要なレンダリング防止のため、memo 化・useMemo・useCallback を実装

## 💦 苦労した点と解決方法

### 音声認識について

まず、いままで音声認識の実装を取り扱ったことがなく、音声認識についての知識がない中でのスタートでした。まず簡単に音声認識の概要を把握しました。（音声入力の受付・音声データの保存・音声データの処理） その後、サンプルになるような記事を読み込んだり、ChatGPT と壁打ちしたりしていました。その中で WebSpeech API や MediaRecorder API を使って音声認識を実装しました。試行錯誤した結果、javaScript ライブラリの RecordRTC がクロスブラウザ対応が充実しており、複数の音声フォーマットに対応していて安定して使えそうだったので採用としました。

### 音声の無音検知について

音声が無音のまま、API エンドポイントに送られたとき無音の音声を元に文字起こしをしており、文字起こしがうまくいかない事象が発生していました。そのため無音を検知する機能が必要と考えました。今回は API 側で検知するようにしました。 OpenAI_API の Whisper で no_speech_threshold という API 側の無音判定閾値を設定して、 音声の無音検知を実装しました。自宅での実験のみで現在もどの閾値が適切か調整中ではありますが、期待通りに無音検知を実装できました。また音声を無音で送ったときにブラウザに無音を通知する機能までできたので良かったです。

## 🚀 今後の展望

### 改善点

-   AI との会話なので、もっとテンポよく会話できるようにする。入力トークン数の制限などでレイテンシーの改善
-   音声認識が、えー、あー、とかの状態を感知したら AI 側が省いて最適化するようになっているので原文のまま取得出来るようにする。
-   音声認識のときに多少の訛りなども認識できるようにする。
-   AI をアイコンだけではなく、ビジュアルキャラクターにしてそれとも会話できるようにする。

### 追加機能

-   ブラウザ間で直接リアルタイムな通信を可能にする Web 標準技術(webRTC)を組み込むことが出来れば、リアルタイムでのやり取りができるようになりそうと考えている。現在技術的に知見がないので、現在は未実装となっている。今後勉強してみて実装したい。
